m4_define(`m4_post_date', `2006-02-20')m4_dnl
m4_define(`m4_post_title', `Visual Effects in &ldquo;The Chronicles of Narnia: The Lion``,'' The Witch and The Wardrobe&rdquo;')m4_dnl
m4_include(`posttrans.m4')m4_dnl
m4_begin_post
<p>
Thanks to Anirban Deb, I attended a presentation yesterday that was given by some of the guys from Rhythm and Hues India where they demonstrated how they created some of the visual effects in the recent movie "The Chronicles of Narnia: The Lion, The Witch and The Wardrobe". It was organised by <a href="http://www.asifaindia.com/">ASIFA India</a> and supported by <a href="http://www.cgtantra.com/">CG Tantra</a>, <a href="http://www.animationxpress.com/">Animation 'Xpress</a> and <a href="http://www.womeninanimation.org/">Women In Animation</a>. The auditorium was full of interested people - students from the various animation training institutes in Bangalore, professionals from the animation and visual effects industry and "outsiders" (like yours truly) who were just curious about such things.  The presentation was enlightening in several ways. Some interesting tidbits included: <ul> <li>The lion Aslan was entirely CG! There were around 5 million strands of hair on this model and around 15 different types of hair. The model comprised the skeleton of the lion, the key muscles on its body, the skin and the fur. Its expressions were modelled on Gregory Peck's role as Atticus Finch in the movie "To Kill a Mockingbird", since they did not know who would provide the voice for Aslan till quite some time into the production. Fortunately for them, Liam Neeson's voice was not too far off the mark for the rendered expressions. </li> <li>They used around 65 different types of characters in the final battle scene. They used the <a href="http://www.massivesoftware.com/">MASSIVE</a> software to simulate a realistic battle scene comprising almost entirely of tens of thousands of animated characters. They used <a href="http://en.wikipedia.org/wiki/Level_of_Detail">Level of Detail</a> (LoD) to reduce the load on their render farm. </li> <li>Their render farm for this project comprised around 2000 machines (I do not remember if they were dual-CPU Pentium 4s or Opterons). They also have a daemon on each employee's workstation that uses the idle time on that workstation to help with the rendering jobs. They use a custom Red Hat and SuSE distribution and <i>all</i> their employees use Linux on their desktop. All their assets are stored on centrally available file servers that virtualise access using a custom asset locator instead of ordinary file paths (this lets them easily move around stuff when discs get full for example). <i>All</i> the tools in their pipeline have been created in-house. All of this allows them to add capacity to their render farm as needed without wasting a tonne of money in software licenses or being at the mercy of a vendor to implement a feature they need immediately. It also insulates them from vendor bankruptcies which is apparently common in this industry. </li> <li>Since rendering each frame in a shot was computationally very expensive, they used several aggressive techniques to reduce re-renders. For example, while using something like <a href="http://en.wikipedia.org/wiki/Phong_shading">Phong shading</a>, instead of rendering the whole frame in one go, they would separately keep the contributions of ambient, diffuse and specular (from <i>each of the lights</i> in the frame) and then combine these in a computationally trivial step to create the final image. This allowed their artists to tweak the colour, intensity, etc. of each light source to get the perfect look without having to submit a new job to the render farm. </li> <li>Blend shapes are simple to use, but inaccurate, means to show character movement and expressions. Muscle deformations are more complex to use but volumetrically accurate. These guys created a tool that interpreted blend shapes to derive the corresponding muscle deformations to get the best of both worlds. </li> <li>Normally PCs use 8-bits of intensity levels per Red, Green and Blue component to illuminate a pixel. Apparently this is not sufficient and produces banding effects due to loss of precision over several calculations. They were therefore using a 16-bit logarithmic intensity level per component for all intermediate calculations. </li> <li>If one is to believe the presenters, apparently the visual effects guys are pretty low in the pecking order in a movie production. Something as simple as telling the director to not use bright green as the key colour when the background itself is green sunlit grass was beyond them. </li> <li>I didn't understand it fully, but they apparently made a monetary loss on this project. It is also apparently a very low margin, high effort business requiring extremely talented artists. </li></ul> It is also heartening to know that <a href="http://www.blender3d.com/">Blender 3D</a> is getting better and better, especially for character animation, and we can actually do <i>some</i> of this stuff at home. <a href="http://www.synfig.com/">Synfig</a>, a 2D vector animation tool, also became Free recently though I do not know how good it is.
<p>
(<a href="http://www.advogato.org/person/rmathew/diary/146.html">Originally posted on Advogato</a>.)
m4_end_post
